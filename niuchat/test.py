__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import asyncio
import io
import time
import pandas as pd
import config
from utils.chromadb_helpers import init_chromadb
from utils.llm import Message, RoleEnum, get_embedding, llmchat
from utils.util import get_knowledge_prompt, p, get_language_name

# å¾—åˆ°ä¸Šä¸‹æ–‡
async def get_chat_context(userquestion):
    chat_context = []
    
    detected_language = get_language_name(userquestion)
    
    # å¾—åˆ°ç³»ç»Ÿæç¤ºè¯
    chat_context.append(Message(role=RoleEnum.system, content=config.LLM_SYSTEM_PROMPT.format(language=detected_language)))

    retrieved_knowledge = await get_knowledge_prompt(userquestion)
    chat_context.append(Message(role=RoleEnum.user, content=retrieved_knowledge))
    return chat_context

async def ai_retun(question):
    chat_context = await get_chat_context(question)
    
    print(chat_context)
    
    text_buffer = io.StringIO()
    async for eachtoken in llmchat(chat_context):
        text_buffer.write(eachtoken)
    return text_buffer.getvalue()

async def embedding(question):
    embedding = await get_embedding(question)
    return embedding

# å…¨é‡æ„å»ºåµŒå…¥ä¿å­˜çš„excel
async def generate_embedding_save_to_excel():
    with open("./newqa.xlsx", 'rb') as f:
        df = pd.read_excel(f, index_col=0)

    # 1. åˆ›å»ºä¸€ä¸ª Semaphore å¯¹è±¡ï¼Œå®ƒæŒæœ‰ pool_size ä¸ªè®¸å¯è¯
    semaphore = asyncio.Semaphore(20)
    
    # 2. åˆ›å»ºä¸€ä¸ªâ€œå·¥äººâ€åç¨‹ï¼Œå®ƒä¼šå…ˆè·å–è®¸å¯è¯å†æ‰§è¡Œä»»åŠ¡
    async def worker(task_name, text):
        # async with ä¼šè‡ªåŠ¨è·å–å’Œé‡Šæ”¾ semaphore
        async with semaphore:
            # æ­¤æ—¶ï¼Œæˆ‘ä»¬ä¿è¯äº†æœ€å¤šåªæœ‰ pool_size ä¸ª worker åœ¨åŒæ—¶æ‰§è¡Œä¸‹é¢çš„ä»£ç 
            print(f"[{time.strftime('%H:%M:%S')}] ğŸ”‘ {task_name}: å·²è·å¾—è®¸å¯è¯ï¼Œè¿›å…¥å·¥ä½œåŒº")
            return await embedding(text)

    tasks = [
        worker(f"ä»»åŠ¡: {row.Index}", row.question) 
        for row in df.itertuples() 
    ]

    # 4. ä½¿ç”¨ asyncio.gather å¹¶å‘è¿è¡Œæ‰€æœ‰â€œå·¥äººâ€ä»»åŠ¡
    embedding_results = await asyncio.gather(*tasks)

    # 5. å°†ç»“æœèµ‹å€¼ç»™æ–°åˆ—
    df['embedding'] = embedding_results

    with open("newqa3.xlsx", "wb") as r:
        df.to_excel(r)

# æµ‹è¯•å¤§è¯­è¨€æ¨¡å‹
async def test_llm():
    with open("./newqa.xlsx", 'rb') as f:
        faqdf = pd.read_excel(f, index_col=0)

    if config.USE_CHROMADB:
        init_chromadb(datasets=faqdf)

    # userquestion = "åŒä¸€ç”¨æˆ·æ˜¯å¦å¯ä»¥æ³¨å†Œå¤šä¸ªè´¦æˆ·ï¼Ÿ"
    # final_prompt = await get_knowledge_prompt(userquestion)
    # print(final_prompt)
    # print(await ai_retun(userquestion))

    with open("./çœŸå®ç”¨æˆ·é—®ç­”.csv", 'rb') as f:
        df = pd.read_csv(f, index_col=0)

    df = df.iloc[:10]
    semaphore = asyncio.Semaphore(100)

    async def worker(task_name, text):
        async with semaphore:
            print(f"å¼€å§‹ä»»åŠ¡: {task_name}")
            return await ai_retun(text)

    tasks = [
        worker(task_name=f"é—®é¢˜ = {row.question} ID = {row.Index}", text=row.question)
        for row in df.itertuples()
    ]

    llm_results = await asyncio.gather(*tasks)

    df['llm_result'] = llm_results

    save = df.loc[:, ['question', 'answer', 'llm_result']]
    with open("result.json", "wb") as f:
        save.to_json(f, indent=4, force_ascii=False, orient="records")

asyncio.run(test_llm())
